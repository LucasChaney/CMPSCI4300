{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cf20c51f",
      "metadata": {
        "id": "cf20c51f"
      },
      "source": [
        "Kaggle Dataset Diabetes, Hypertensionand Stroke Prediction:https://www.kaggle.com/datasets/prosperchuks/health-dataset/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "462f904f",
      "metadata": {
        "id": "462f904f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b1edd9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2c97ca9",
      "metadata": {
        "id": "a2c97ca9"
      },
      "source": [
        "Used to shuffle the dataset so that the predictions are not unevely measured."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f3e61ea",
      "metadata": {
        "id": "0f3e61ea"
      },
      "outputs": [],
      "source": [
        "#Change these paths as needed\n",
        "data_path = \"diabetes_data.csv\"\n",
        "shuffled_data_path =  \"shuffled_diabetes_data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ee087b0",
      "metadata": {
        "id": "3ee087b0"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "#Shuffle the dataframe\n",
        "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "#Save the shuffled dataframe to a new CSV file\n",
        "df_shuffled.to_csv(shuffled_data_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4535834",
      "metadata": {
        "id": "a4535834"
      },
      "source": [
        "# Phase 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af983b96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "af983b96",
        "outputId": "6768cc43-6af3-4b75-8b26-5eb3c101e5c6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Display dataset shape and first few rows\n",
        "print(\"Dataset shape:\", df_shuffled.shape)\n",
        "print(df_shuffled.head())\n",
        "\n",
        "# Check for null values\n",
        "print(\"\\nMissing values:\")\n",
        "print(df_shuffled.isnull().sum())\n",
        "\n",
        "# Target column: Diabetes (0 or 1)\n",
        "# Separate features and target\n",
        "X = df_shuffled.drop(columns=['Diabetes'])\n",
        "y = df_shuffled['Diabetes']\n",
        "\n",
        "# Normalize numeric input features\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Split into training (90%) and validation (10%) sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "# Print resulting shapes\n",
        "print(\"\\nTraining set shape:\", X_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape)\n",
        "\n",
        "# Plot feature distribution examples\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(X['BMI'], kde=True, bins=30)\n",
        "plt.title('BMI Distribution')\n",
        "plt.xlabel('BMI')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x=y)\n",
        "plt.title('Target Label Distribution (Diabetes)')\n",
        "plt.xlabel('Diabetes (0 = No, 1 = Yes)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c86c105",
      "metadata": {
        "id": "7c86c105"
      },
      "source": [
        "# Phase 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff99e254",
      "metadata": {
        "id": "ff99e254"
      },
      "source": [
        "Overfitting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89d5060b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store results for Phase 2\n",
        "overfitting_results = []\n",
        "\n",
        "\n",
        "\n",
        "class EarlyStoppingByAccuracy(Callback):\n",
        "    def __init__(self, monitor='accuracy', value=0.99):\n",
        "        super().__init__()\n",
        "        self.monitor = monitor\n",
        "        self.value = value\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get(self.monitor) >= self.value:\n",
        "            print(f\"Reached {self.value*100:.1f}% training accuracy. Stopping training.\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8955df3c",
      "metadata": {
        "id": "8955df3c"
      },
      "outputs": [],
      "source": [
        "def build_and_train_overfit_model(hidden_layers, neurons_per_layer, input_dim, epochs=1000, batch_size=32):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(input_dim,)))\n",
        "    for _ in range(hidden_layers):\n",
        "        model.add(Dense(neurons_per_layer, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "                  loss=BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    early_stop = EarlyStoppingByAccuracy(monitor='accuracy', value=0.99)\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(X_scaled, y, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stop])\n",
        "    end_time = time.time()\n",
        "\n",
        "    final_acc = history.history['accuracy'][-1]\n",
        "    elapsed_time = end_time - start_time\n",
        "    \n",
        "    print(f\"Training time: {elapsed_time:.2f} seconds\")\n",
        "    overfitting_results.append((f\"{neurons_per_layer}-neurons x {hidden_layers}-layers\", final_acc))\n",
        "\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cba672fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cba672fd",
        "outputId": "07821877-4ee7-47e4-b8ac-2ba8b84db814"
      },
      "outputs": [],
      "source": [
        "# Testing model sizes\n",
        "layer_sizes = [5, 6, 7]\n",
        "neuron_options = [512, 1024]\n",
        "\n",
        "for layers in layer_sizes:\n",
        "    for neurons in neuron_options:\n",
        "        print(f\"Training model: {neurons} neurons x {layers} layers\")\n",
        "        model, history = build_and_train_overfit_model(hidden_layers=layers, neurons_per_layer=neurons, input_dim=X_scaled.shape[1])\n",
        "        if history.history['accuracy'][-1] >= 0.99:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf51648",
      "metadata": {
        "id": "caf51648"
      },
      "outputs": [],
      "source": [
        "# Show Overfitting Results\n",
        "print(\"\\nOverfitting Results:\")\n",
        "for config, acc, elapsed_time in overfitting_results:\n",
        "    print(f\"{config} => Training Accuracy: {acc:.4f}, Time: {elapsed_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35eb02b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot accuracy vs model size\n",
        "labels = [config for config, acc in overfitting_results]\n",
        "accuracies = [acc for config, acc in overfitting_results]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(labels, accuracies, marker='o')\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.title(\"Training Accuracy vs. Model Architecture\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05d35e8f",
      "metadata": {},
      "source": [
        "# Phase 3: Model Selection and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26115536",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store evaluation results\n",
        "evaluation_results = []\n",
        "\n",
        "# Wrapper function to build and train model for Phase 3\n",
        "#This function is built from the same function in Phase 2\n",
        "def train_and_evaluate_model_phase3(hidden_layers, neurons_per_layer, input_dim, model_name):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(input_dim,)))\n",
        "    for _ in range(hidden_layers):\n",
        "        model.add(Dense(neurons_per_layer, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "    checkpoint = ModelCheckpoint(f'{model_name}_best.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
        "    model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[checkpoint], verbose=0)\n",
        "\n",
        "    preds = np.round(model.predict(X_val)).flatten()\n",
        "    acc = accuracy_score(y_val, preds)\n",
        "    precision = precision_score(y_val, preds)\n",
        "    recall = recall_score(y_val, preds)\n",
        "    f1 = f1_score(y_val, preds)\n",
        "    params = model.count_params()\n",
        "    evaluation_results.append((model_name, acc, precision, recall, f1, params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "882107ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Random Baseline Classifier\n",
        "random_preds = np.random.choice([0, 1], size=y_val.shape)\n",
        "random_acc = accuracy_score(y_val, random_preds)\n",
        "random_precision = precision_score(y_val, random_preds)\n",
        "random_recall = recall_score(y_val, random_preds)\n",
        "random_f1 = f1_score(y_val, random_preds)\n",
        "evaluation_results.append((\"Random Baseline\", random_acc, random_precision, random_recall, random_f1, \"-\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5757464f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Logistic Regression (no hidden layers)\n",
        "train_and_evaluate_model_phase3(hidden_layers=0, neurons_per_layer=1, input_dim=X_train.shape[1], model_name=\"Logistic Regression\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6fc1604",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Neural Network Architectures to Evaluate\n",
        "architectures = {\n",
        "    \"64-32-16-8-1\": [64, 32, 16, 8],\n",
        "    \"32-16-8-1\": [32, 16, 8],\n",
        "    \"16-8-1\": [16, 8],\n",
        "    \"8-1\": [8],\n",
        "    \"4-1\": [4],\n",
        "    \"2-1\": [2]\n",
        "}\n",
        "\n",
        "for name, layers in architectures.items():\n",
        "    hidden_layers = len(layers)\n",
        "    neurons_per_layer = layers[0]  # We pass the size of the first hidden layer\n",
        "    train_and_evaluate_model_phase3(hidden_layers, neurons_per_layer, X_train.shape[1], model_name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26a4364a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summarize Results\n",
        "results_df = pd.DataFrame(evaluation_results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"# Parameters\"])\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52a362cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify Best Model\n",
        "best_model = results_df.sort_values(by=\"Accuracy\", ascending=False).iloc[0]\n",
        "print(\"\\nBest Performing Model:\")\n",
        "print(best_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41cdf094",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Accuracy Comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(results_df['Model'], results_df['Accuracy'])\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Validation Accuracy by Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
