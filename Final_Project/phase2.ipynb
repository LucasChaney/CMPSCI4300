{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d3b328",
   "metadata": {},
   "source": [
    "Phase 2: Build a model to overfit the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9bfad09",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd50270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed dataset\n",
    "df = pd.read_csv('processed_spreadspoke_scores.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['spread_covered'])\n",
    "y = df['spread_covered']\n",
    "\n",
    "# Convert target to numpy array\n",
    "y = y.values\n",
    "\n",
    "# Track models and their accuracy\n",
    "results = []\n",
    "\n",
    "# Define function to build and train model\n",
    "def train_and_evaluate_model(hidden_layers, neurons_per_layer, input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons_per_layer, activation='relu', input_dim=input_dim))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(neurons_per_layer, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X, y, epochs=100, verbose=0)\n",
    "    final_acc = history.history['accuracy'][-1]\n",
    "    results.append((f\"{neurons_per_layer}-neuron x {hidden_layers}-layer\", final_acc))\n",
    "    return model, history\n",
    "\n",
    "# Test various model sizes\n",
    "layer_sizes = [1, 2, 3]\n",
    "neuron_options = [1, 2, 4, 8, 16, 32, 64]\n",
    "\n",
    "for layers in layer_sizes:\n",
    "    for neurons in neuron_options:\n",
    "        print(f\"Training model: {neurons} neurons x {layers} layers\")\n",
    "        model, history = train_and_evaluate_model(layers, neurons, X.shape[1])\n",
    "        if history.history['accuracy'][-1] >= 0.99:\n",
    "            break  # stop early if we overfit\n",
    "\n",
    "# Show results\n",
    "print(\"\\nOverfitting Results:\")\n",
    "for config, acc in results:\n",
    "    print(f\"{config} => Training Accuracy: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
