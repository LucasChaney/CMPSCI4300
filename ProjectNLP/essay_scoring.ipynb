{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['essay_id', 'full_text', 'score'], dtype='object')\n",
      "  essay_id                                          full_text  score\n",
      "0  000d118  Many people have car where they live. The thin...      3\n",
      "1  000fe60  I am a scientist at NASA that is discussing th...      3\n",
      "2  001ab80  People always wish they had the same technolog...      4\n",
      "3  001bdc0  We all heard about Venus, the planet without a...      4\n",
      "4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training data\n",
    "train_path = r'nlp_project_train.csv'\n",
    "df = pd.read_csv(train_path)\n",
    "\n",
    "# Quick peek at the data\n",
    "print(df.columns)\n",
    "print(df[[\"essay_id\",\"full_text\",\"score\"]].head())\n",
    "\n",
    "#Remove placeholder essays like \"PROPER_NAME\"\n",
    "df = df[~df['full_text'].str.contains(\"PROPER_NAME\", na=False)]\n",
    "\n",
    "# Reset index for safety\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this to preview an essay of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay ID: 000d118\n",
      "Essay Preview:\n",
      " Many people have car where they live. The thing they don't know is that when you use a car alot of thing can happen like you can get in accidet or the smoke that the car has is bad to breath on if someone is walk but in VAUBAN,Germany they dont have that proble because 70 percent of vauban's families do not own cars,and 57 percent sold a car to move there. Street parkig ,driveways and home garages are forbidden on the outskirts of freiburd that near the French and Swiss borders. You probaly won'\n"
     ]
    }
   ],
   "source": [
    "print(\"Essay ID:\", df.loc[0, 'essay_id'])\n",
    "print(\"Essay Preview:\\n\", df.loc[0, 'full_text'][:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "df = pd.read_csv(r'nlp_project_train.csv')\n",
    "df = df[['essay_id', 'full_text', 'score']]\n",
    "df = df[~df['full_text'].str.contains(\"PROPER_NAME\", na=False)]\n",
    "# Remove comment to set cap of 1000 essays for testing.\n",
    "#df = df.head(1000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['full_text'])  # Sparse matrix (num_essays x vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(X)\n",
    "\n",
    "# Set diagonal (self-similarity) to 0 so we don't pick them\n",
    "np.fill_diagonal(similarity_matrix, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_heap = []\n",
    "\n",
    "for i in range(similarity_matrix.shape[0]):\n",
    "    for j in range(i + 1, similarity_matrix.shape[0]):\n",
    "        sim = similarity_matrix[i, j]\n",
    "        if sim >= 0.999:  # Skip near-exact duplicates\n",
    "            continue\n",
    "        if len(top_5_heap) < 5:\n",
    "            heapq.heappush(top_5_heap, (sim, i, j))\n",
    "        else:\n",
    "            heapq.heappushpop(top_5_heap, (sim, i, j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Essay 29aa983 vs Essay 6d25307\n",
      "Similarity Score: 0.9219\n",
      "Essay 1 Preview: A new hom  whould you send someone to explore venus with the technology that we haave  right now? the author of the article  the challege of exploring\n",
      "Essay 2 Preview: Benefits of Researching a New planet  Whould you send someone to explore venus with even if we don't have the technology necessary?The author of the a\n",
      "\n",
      "Essay 7f55753 vs Essay 9985008\n",
      "Similarity Score: 0.8890\n",
      "Essay 1 Preview: teacher asks:  What is an electoral college?  my answer:  The electoral college is a process, not a place...  The founding fathers etablished it in th\n",
      "Essay 2 Preview: In the first source its explain what a Electoral College is which is not a place it's a process the finding fathers established it in the Constitution\n",
      "\n",
      "Essay 4d0c575 vs Essay e026924\n",
      "Similarity Score: 0.8873\n",
      "Essay 1 Preview: Dear state senator i am writing to you because i would like to try a different way to select the president by using the popular. most states have a \"w\n",
      "Essay 2 Preview: Dear senator,  What are the chances in favor of keeping the electoral college or changing to election by popular vote for the president of the united \n",
      "\n",
      "Essay 7cdf8b2 vs Essay 84a1b1a\n",
      "Similarity Score: 0.8864\n",
      "Essay 1 Preview: \"Does Electoral College Work?\"  Today I am going to write about how electoral colleges work. The Electrical College is a process, not a place. The fou\n",
      "Essay 2 Preview: Dear state senator,  Do you think that we should keep the Electoral College? We should keep the electoral college because the founding fathers establi\n",
      "\n",
      "Essay 287ed5e vs Essay 84a1b1a\n",
      "Similarity Score: 0.8773\n",
      "Essay 1 Preview: I think the Electoral college is a good way to vote for the president or vice president because i think without the Electoral college, we wouldn't hav\n",
      "Essay 2 Preview: Dear state senator,  Do you think that we should keep the Electoral College? We should keep the electoral college because the founding fathers establi\n"
     ]
    }
   ],
   "source": [
    "top_5 = sorted(top_5_heap, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "for sim, i, j in top_5:\n",
    "    print(f\"\\nEssay {df.iloc[i]['essay_id']} vs Essay {df.iloc[j]['essay_id']}\")\n",
    "    print(f\"Similarity Score: {sim:.4f}\")\n",
    "    print(\"Essay 1 Preview:\", df.iloc[i]['full_text'][:150].replace('\\n', ' '))\n",
    "    print(\"Essay 2 Preview:\", df.iloc[j]['full_text'][:150].replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This part is used so that I can easily get a full essay to put it in an online comparer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay ID: 6d25307\n",
      "\n",
      "Full Essay Text:\n",
      "\n",
      "Benefits of Researching a New planet\n",
      "\n",
      "Whould you send someone to explore venus with even if we don't have the technology necessary?The author of the article \"The Challenge of Exploring Venus\" has made some good point about why we should send if not but machines to explore Venus.The author believes that it would be beneficial for us to explor Venus using the technology that we have right now and the new technology that it has recently been invented for example:The mechamical computers,The new Idea that NASA has come up to and considering Venus as a moving planet.\n",
      "\n",
      "First of all the author explains the old use of old technology called mechanical computer.This computers played an important role during the 1940s Word War two by making calculations using gears and levers, no electronics were needed for this computers. The author explains why the computer could be very useful to explore Venus by saying that this computer are very powerful,flexible, and quick. The only problem would be that the computers are very delicated when is put to extreme conditions.\n",
      "\n",
      "Secondly the author mentions an idea that NASA has come up to that could really help the explorationg of Venus.The author mentions the idea of NASA of making a vehicle that could help the exploration of Venus by Hovering the surface of Venus.The author explains that Venus has a very high temperature but the vehicle would hover 30 miles overand avoid the bad ground. This idea that NASA has come up to its a good way for humans to visit and explore Venus.\n",
      "\n",
      "Lastly the author believes tha Venus is not to different from earth and in the right conditions, humans could be living in Venus. The author mentions how scientists believed that Venus is the planet with the more like earth and how it could posibly at one time had oceans. Research on Venus could also explain that Venus at one point could have and maintain life forms. This is why it would be worthy for humans to explore Venus becuase it could posibly be the next earth.\n",
      "\n",
      "In conclution the author brought many points of why we sould keep on exploring Venus from technology to even a new planet.The author has a very good understanding about the exploration Venus and believed that it would be a good investment to explore it.\n"
     ]
    }
   ],
   "source": [
    "essay_id = '6d25307'  # <- target essay ID\n",
    "\n",
    "# Find the matching row\n",
    "row = df[df['essay_id'] == essay_id]\n",
    "\n",
    "# Display full essay text\n",
    "if not row.empty:\n",
    "    print(\"Essay ID:\", essay_id)\n",
    "    print(\"\\nFull Essay Text:\\n\")\n",
    "    print(row.iloc[0]['full_text'])\n",
    "else:\n",
    "    print(f\"No essay found with ID {essay_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukec\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Essay_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lukec\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Essay_ID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEssay 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_sentence1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEssay 2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_sentence2\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mcompare_essays_by_id\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m29aa983\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m6d25307\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mcompare_essays_by_id\u001b[39m\u001b[34m(id1, id2, df)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompare_essays_by_id\u001b[39m(id1, id2, df):\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# Lookup essays by ID\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     essay1_row = df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEssay_ID\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m == id1]\n\u001b[32m     18\u001b[39m     essay2_row = df[df[\u001b[33m\"\u001b[39m\u001b[33mEssay_ID\u001b[39m\u001b[33m\"\u001b[39m] == id2]\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m essay1_row.empty \u001b[38;5;129;01mor\u001b[39;00m essay2_row.empty:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lukec\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lukec\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Essay_ID'"
     ]
    }
   ],
   "source": [
    "# This is a model made by ChatGPT to test the similarity of\n",
    "# two essays provided. This is not meant to be used to find the \n",
    "# actually score for the methods needed for the project. Just a secondary\n",
    "# testing method to check my scores\n",
    "%pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(r'nlp_project_train.csv')\n",
    "\n",
    "# Load the transformer model once (globally)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def compare_essays_by_id(id1, id2, df):\n",
    "    # Lookup essays by ID\n",
    "    essay1_row = df[df[\"Essay_ID\"] == id1]\n",
    "    essay2_row = df[df[\"Essay_ID\"] == id2]\n",
    "\n",
    "    if essay1_row.empty or essay2_row.empty:\n",
    "        return f\"One or both Essay IDs not found: {id1}, {id2}\"\n",
    "\n",
    "    essay1 = essay1_row[\"Essay_Text\"].values[0]\n",
    "    essay2 = essay2_row[\"Essay_Text\"].values[0]\n",
    "\n",
    "    # === SentenceTransformer similarity (THIS IS WHERE IT GOES) ===\n",
    "    embeddings = model.encode([essay1, essay2])\n",
    "    score = util.cos_sim(embeddings[0], embeddings[1]).item()\n",
    "\n",
    "    # Extract first sentences\n",
    "    first_sentence1 = essay1.strip().split('.')[0]\n",
    "    first_sentence2 = essay2.strip().split('.')[0]\n",
    "\n",
    "    # Output\n",
    "    print(f\"Essay {id1} vs Essay {id2}\")\n",
    "    print(f\"Similarity Score: {score:.4f}\")\n",
    "    print(f\"Essay 1: {first_sentence1}\")\n",
    "    print(f\"Essay 2: {first_sentence2}\")\n",
    "\n",
    "compare_essays_by_id(\"29aa983\", \"6d25307\", df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
