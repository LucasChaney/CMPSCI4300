{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-cloud-storage\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7vIus0y-Cdk",
        "outputId": "839ecf9f-5ae1-4471-830a-dd25591e01dd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.24.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (1.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.69.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2025.1.31)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "HmkFes_U-VpE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from google.cloud import storage\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "project_id = 'essay-scoring-455902'\n",
        "bucket_name = 'nlp-eassay-bucket-2025'\n",
        "\n",
        "client = storage.Client(project=project_id)\n",
        "bucket = client.get_bucket(bucket_name)\n",
        "\n",
        "blob = bucket.blob('nlp_project_train.csv')\n",
        "blob.download_to_filename('nlp_project_train.csv')  # This saves the file locally in Colab\n"
      ],
      "metadata": {
        "id": "s-d3kypsAJtQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4l5qEap9L2U",
        "outputId": "8e86a116-4f64-4d39-cc9e-4c85ea3c042f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['essay_id', 'full_text', 'score'], dtype='object')\n",
            "  essay_id                                          full_text  score\n",
            "0  000d118  Many people have car where they live. The thin...      3\n",
            "1  000fe60  I am a scientist at NASA that is discussing th...      3\n",
            "2  001ab80  People always wish they had the same technolog...      4\n",
            "3  001bdc0  We all heard about Venus, the planet without a...      4\n",
            "4  002ba53  Dear, State Senator\\r\\n\\r\\nThis is a letter to...      3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the training data\n",
        "train_path = r'nlp_project_train.csv'\n",
        "df = pd.read_csv(train_path)\n",
        "\n",
        "# Quick peek at the data\n",
        "print(df.columns)\n",
        "print(df[[\"essay_id\",\"full_text\",\"score\"]].head())\n",
        "\n",
        "#Remove placeholder essays like \"PROPER_NAME\"\n",
        "df = df[~df['full_text'].str.contains(\"PROPER_NAME\", na=False)]\n",
        "\n",
        "# Reset index for safety\n",
        "df.reset_index(drop=True, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdkVzDLl9L2V"
      },
      "source": [
        "# Use this to preview an essay of choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhLiqiOg9L2W",
        "outputId": "3a994809-4fe2-4279-ea6f-20628c358590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Essay ID: 000d118\n",
            "Essay Preview:\n",
            " Many people have car where they live. The thing they don't know is that when you use a car alot of thing can happen like you can get in accidet or the smoke that the car has is bad to breath on if someone is walk but in VAUBAN,Germany they dont have that proble because 70 percent of vauban's families do not own cars,and 57 percent sold a car to move there. Street parkig ,driveways and home garages are forbidden on the outskirts of freiburd that near the French and Swiss borders. You probaly won'\n"
          ]
        }
      ],
      "source": [
        "print(\"Essay ID:\", df.loc[0, 'essay_id'])\n",
        "print(\"Essay Preview:\\n\", df.loc[0, 'full_text'][:500])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqQqX-FY9L2W"
      },
      "source": [
        "## Method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "d2SwCIXd9L2X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import heapq\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3GUx3eck9L2X"
      },
      "outputs": [],
      "source": [
        "# Load the training data\n",
        "df = pd.read_csv(r'nlp_project_train.csv').head(5000)\n",
        "df = df[['essay_id', 'full_text', 'score']]\n",
        "df = df[~df['full_text'].str.contains(\"PROPER_NAME\", na=False)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B4ABnEp69L2X"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(df['full_text'])  # Sparse matrix (num_essays x vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BE7P1qk29L2X"
      },
      "outputs": [],
      "source": [
        "similarity_matrix = cosine_similarity(X)\n",
        "\n",
        "# Set diagonal (self-similarity) to 0 so we don't pick them\n",
        "np.fill_diagonal(similarity_matrix, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ARqC1iiO9L2X"
      },
      "outputs": [],
      "source": [
        "# Simple word overlap function\n",
        "def simple_word_overlap(text1, text2):\n",
        "    words1 = set(text1.lower().split())\n",
        "    words2 = set(text2.lower().split())\n",
        "    if not words1 or not words2:\n",
        "        return 0.0\n",
        "    return len(words1 & words2) / len(words1 | words2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "mZCs0GOr9L2X",
        "outputId": "75e4f5f8-500d-4d53-8981-a47e437dc6fd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5fb65b4e9cb8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcosine_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1741\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    199\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         X = check_array(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         array = _ensure_sparse_format(\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(sparse_container, accept_sparse, dtype, copy, ensure_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    647\u001b[0m             )\n\u001b[1;32m    648\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    650\u001b[0m                 \u001b[0msparse_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# Cython implementation to prevent false positives and provide a detailed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# error message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mfirst_pass_isfinite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfirst_pass_isfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize heaps\n",
        "top_5_heap = []\n",
        "false_positive_heap = []\n",
        "false_negative_heap = []\n",
        "count = 0\n",
        "interval = 1000\n",
        "start_time = time.time()\n",
        "\n",
        "# Pairwise comparison loop\n",
        "for i in range(X.shape[0]):\n",
        "    for j in range(i + 1, X.shape[0]):\n",
        "        cosine_score = cosine_similarity(X[i], X[j])[0][0]\n",
        "        count += 1\n",
        "\n",
        "        if count % interval == 0:\n",
        "            elapsed_time = time.time() - start_time\n",
        "            mins, secs = divmod(elapsed_time, 60)\n",
        "            print(f\"Processed {count} pairs - elsaped time {mins}:{secs}\")\n",
        "\n",
        "        if cosine_score >= 0.999:\n",
        "            continue  # Skip near-duplicates\n",
        "\n",
        "        # Top 5 by cosine similarity\n",
        "        if len(top_5_heap) < 5:\n",
        "            heapq.heappush(top_5_heap, (cosine_score, i, j))\n",
        "        else:\n",
        "            heapq.heappushpop(top_5_heap, (cosine_score, i, j))\n",
        "\n",
        "        # Real-time validation: compute overlap\n",
        "        overlap_score = simple_word_overlap(df.iloc[i]['full_text'], df.iloc[j]['full_text'])\n",
        "\n",
        "        # False Positive: high cosine, low overlap\n",
        "        if cosine_score >= 0.85 and overlap_score < 0.3:\n",
        "            heapq.heappush(false_positive_heap, (cosine_score, i, j, overlap_score))\n",
        "            false_positive_heap = sorted(false_positive_heap, reverse=True)[:2]\n",
        "\n",
        "        # False Negative: low cosine, high overlap\n",
        "        if cosine_score < 0.4 and overlap_score >= 0.6:\n",
        "            heapq.heappush(false_negative_heap, (overlap_score, i, j, cosine_score))\n",
        "            false_negative_heap = sorted(false_negative_heap, reverse=True)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slXAUyHF9L2Y",
        "outputId": "e1caf7a2-8ebe-407f-bd8e-0349e1fbd045"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TOP 5 SIMILAR ESSAY PAIRS\n",
            "\n",
            "Essay 0036253 vs Essay e35f6ff\n",
            "Cosine Similarity: 0.7500\n",
            "Essay 1 Preview: The challenge of exploring Venus  This storie is about the challeng of exploring Venus. The auhor talked how venus is closest planet in earth. The aut\n",
            "Essay 2 Preview: The author does not support his idea well that studiying Venus is a worthy pursuit despite the dangers. The author talks about people being facinated \n",
            "\n",
            "Essay 0036253 vs Essay 0c0463c\n",
            "Cosine Similarity: 0.7353\n",
            "Essay 1 Preview: The challenge of exploring Venus  This storie is about the challeng of exploring Venus. The auhor talked how venus is closest planet in earth. The aut\n",
            "Essay 2 Preview: Studying Venus seems almost impossible with all the risks, but the author of \"The Challenge of Exploring Venus\" suggests that Venus is a worthy pursui\n",
            "\n",
            "Essay 0036253 vs Essay 1284ac4\n",
            "Cosine Similarity: 0.7326\n",
            "Essay 1 Preview: The challenge of exploring Venus  This storie is about the challeng of exploring Venus. The auhor talked how venus is closest planet in earth. The aut\n",
            "Essay 2 Preview: The Challenge Of Exploring Venus  The story \"The Challenge of Exploring Venus\", is about the planet Venus. Venus is a second planet from the sun, is o\n",
            "\n",
            "Essay 0036253 vs Essay f95baca\n",
            "Cosine Similarity: 0.7324\n",
            "Essay 1 Preview: The challenge of exploring Venus  This storie is about the challeng of exploring Venus. The auhor talked how venus is closest planet in earth. The aut\n",
            "Essay 2 Preview: I claim that the author explained well about studying Venus is a worthy pursuit even though it's dangerous.  The author explained a lot about why scie\n",
            "\n",
            "Essay 0036253 vs Essay 2d356a1\n",
            "Cosine Similarity: 0.7313\n",
            "Essay 1 Preview: The challenge of exploring Venus  This storie is about the challeng of exploring Venus. The auhor talked how venus is closest planet in earth. The aut\n",
            "Essay 2 Preview: The \"Evening Star\" as the author from \"The Challenges of Exploring Venus\" is another name for venus. Venus known for being inhospitable to humans has \n",
            "\n",
            "POTENTIAL FALSE POSITIVES\n",
            "\n",
            "POTENTIAL FALSE NEGATIVES\n"
          ]
        }
      ],
      "source": [
        "# Display results\n",
        "print(\"TOP 5 SIMILAR ESSAY PAIRS\")\n",
        "top_5 = sorted(top_5_heap, key=lambda x: x[0], reverse=True)\n",
        "for sim, i, j in top_5:\n",
        "    print(f\"\\nEssay {df.iloc[i]['essay_id']} vs Essay {df.iloc[j]['essay_id']}\")\n",
        "    print(f\"Cosine Similarity: {sim:.4f}\")\n",
        "    print(\"Essay 1 Preview:\", df.iloc[i]['full_text'][:150].replace('\\n', ' '))\n",
        "    print(\"Essay 2 Preview:\", df.iloc[j]['full_text'][:150].replace('\\n', ' '))\n",
        "\n",
        "print(\"\\nPOTENTIAL FALSE POSITIVES\")\n",
        "for sim, i, j, overlap in false_positive_heap:\n",
        "    print(f\"\\nEssay {df.iloc[i]['essay_id']} vs Essay {df.iloc[j]['essay_id']}\")\n",
        "    print(f\"Cosine: {sim:.4f}, Overlap: {overlap:.4f}\")\n",
        "    print(\"Essay 1 Preview:\", df.iloc[i]['full_text'][:150].replace('\\n', ' '))\n",
        "    print(\"Essay 2 Preview:\", df.iloc[j]['full_text'][:150].replace('\\n', ' '))\n",
        "\n",
        "print(\"\\nPOTENTIAL FALSE NEGATIVES\")\n",
        "for overlap, i, j, cosine in false_negative_heap:\n",
        "    print(f\"\\nEssay {df.iloc[i]['essay_id']} vs Essay {df.iloc[j]['essay_id']}\")\n",
        "    print(f\"Overlap: {overlap:.4f}, Cosine: {cosine:.4f}\")\n",
        "    print(\"Essay 1 Preview:\", df.iloc[i]['full_text'][:150].replace('\\n', ' '))\n",
        "    print(\"Essay 2 Preview:\", df.iloc[j]['full_text'][:150].replace('\\n', ' '))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuivG_Pa9L2Y"
      },
      "source": [
        "### The part below is a way of testing the Cosine similarity and the actual amount of word overlap between the top 5 pairs of essays. This helps give a look to see if the model is actually working well or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF4964pG9L2Y",
        "outputId": "f995972c-f30c-4500-f421-f6b62d91662a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Essay 29139ff vs Essay 6b51c4c\n",
            "Cosine Similarity: 0.9219\n",
            "Word Overlap Score: 0.1319\n",
            "Flagged as a potential FALSE POSITIVE (high cosine, low overlap)\n",
            "\n",
            "Essay 7d34dd4 vs Essay 9706cf0\n",
            "Cosine Similarity: 0.8890\n",
            "Word Overlap Score: 0.0866\n",
            "Flagged as a potential FALSE POSITIVE (high cosine, low overlap)\n",
            "\n",
            "Essay 4b79d77 vs Essay dc225ea\n",
            "Cosine Similarity: 0.8873\n",
            "Word Overlap Score: 0.1399\n",
            "Flagged as a potential FALSE POSITIVE (high cosine, low overlap)\n",
            "\n",
            "Essay 7b69af5 vs Essay 8291f47\n",
            "Cosine Similarity: 0.8864\n",
            "Word Overlap Score: 0.1788\n",
            "Flagged as a potential FALSE POSITIVE (high cosine, low overlap)\n",
            "\n",
            "Essay 2805912 vs Essay 8291f47\n",
            "Cosine Similarity: 0.8773\n",
            "Word Overlap Score: 0.1000\n",
            "Flagged as a potential FALSE POSITIVE (high cosine, low overlap)\n"
          ]
        }
      ],
      "source": [
        "#This model was inspired by chatGPT and online resources to test the accuracy of the\n",
        "# word by word model above. I will use this again later to continue\n",
        "#Testing further models following the same parameters.\n",
        "'''\n",
        "def simple_word_overlap(text1, text2):\n",
        "    words1 = set(text1.lower().split())\n",
        "    words2 = set(text2.lower().split())\n",
        "    if not words1 or not words2:\n",
        "        return 0.0\n",
        "    return len(words1 & words2) / len(words1 | words2)\n",
        "\n",
        "threshold_cosine = 0.85\n",
        "threshold_overlap = 0.3\n",
        "\n",
        "for sim, i, j in top_5:\n",
        "    essay1 = df.iloc[i]['full_text']\n",
        "    essay2 = df.iloc[j]['full_text']\n",
        "    overlap_score = simple_word_overlap(essay1, essay2)\n",
        "\n",
        "    print(f\"\\nEssay {df.iloc[i]['essay_id']} vs Essay {df.iloc[j]['essay_id']}\")\n",
        "    print(f\"Cosine Similarity: {sim:.4f}\")\n",
        "    print(f\"Word Overlap Score: {overlap_score:.4f}\")\n",
        "\n",
        "    if sim >= threshold_cosine and overlap_score < threshold_overlap:\n",
        "        print(\"Flagged as a potential FALSE POSITIVE (high cosine, low overlap)\")\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}